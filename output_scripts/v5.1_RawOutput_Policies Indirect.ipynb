{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-16T11:06:34.157218700Z",
     "start_time": "2023-10-16T11:06:33.271574200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir('e:\\Downloads (E)\\@Books\\@TPM\\@PDPC\\@data_analysis\\model_build')\n",
    "sys.path.append('e:\\Downloads (E)\\@Books\\@TPM\\@PDPC\\@data_analysis\\model_build')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib.ticker as ticker  ## special scaling stuff\n",
    "import cmasher as cmr\n",
    "import colorcet as cet\n",
    "from importlib import reload  ## for reloading packages\n",
    "import pickle\n",
    "import OFM_postprocess_scripts as post\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# retrieve files from saved pickles\n",
    "model_vers = 'v5.2c1'\n",
    "exps_batchname = 'Policies and Indirect'\n",
    "exps_filename = f'model{model_vers}_exps_{exps_batchname}_'\n",
    "exps_s = post.read_experiments_from_pickle(f'data_output/{exps_filename}.pickleobject')\n",
    "\n",
    "# ref_batchname = \"Reference\"\n",
    "# exps_r = post.read_experiments_from_pickle(f'data_output/{exps_filename }.pickleobject')\n",
    "# reload(post)\n",
    "# extract relevant information from pickled experiment object\n",
    "meta_s = pd.DataFrame.from_dict(exps_s.results_metadata, orient='index')\n",
    "meta_s['p_FlightBans'] = meta_s['p_FlightBans'].fillna(value=500).astype(int)\n",
    "meta_s['p_FlightBans_nom'] = meta_s['p_FlightBans'] - exps_s.c_nominal_ref_date\n",
    "results_s: pd.DataFrame = post.add_extra_metrics(exps_s)\n",
    "\n",
    "# meta_r = pd.DataFrame.from_dict(exps_r.results_metadata, orient='index')\n",
    "# meta_r['p_FlightBans_nom'] = meta_r['p_FlightBans'] - exps_r.c_nominal_ref_date\n",
    "# results_r: pd.DataFrame = post.add_extra_metrics(exps_r)\n",
    "\n",
    "# invert the policy inputs to be relative again (instead of machine-focused)\n",
    "policy_inputs = dict((v, k) for k, v in exps_s.p_flightbans_map.items())  # inversion process\n",
    "exps_s.results_verbose = exps_s.results_postprocess = None\n",
    "# exps_r.results_verbose = exps_r.results_postprocess = None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T11:06:46.866990500Z",
     "start_time": "2023-10-16T11:06:43.803111900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# new one for cumulative\n",
    "# reload(post)\n",
    "# batch_cols = ['cum_infected']\n",
    "# newer system to also include new-infected\n",
    "batch_cols = {'cum_infected': [10000,],}\n",
    "              # 'infected_new': [1000, 5000]}\n",
    "# benchmarks_cum = [10000,] # reverse-find days till metric reaches these value(s)\n",
    "benchmarks_day = np.arange(1,5,1) * 7 # take cumulative on this day\n",
    "# batch_df = results_s[results_s.u_Rzero < 2.0 ].copy()\n",
    "batch_df = results_s\n",
    "batch_out1 = meta_s.copy()\n",
    "\n",
    "# set up recording\n",
    "# table_batch = dict()\n",
    "# out1_namemap = {'cum_infected': 'Icumul',\n",
    "#                 'infected_new': 'Inew'}\n",
    "# table_batch = {'b_cumulative': [],\n",
    "#             'b_day': [], }\n",
    "# new_pivs = {}  # only for debug\n",
    "# New implementation\n",
    "_out1_namemap = {'cum_infected': 'Icumul',\n",
    "                'infected_new': 'Inew'}\n",
    "_metrics_per = ['Dsearch', 'Dvalue'] # what metrics are included per batch\n",
    "batch_names = dict([(f'{_out1_namemap[batch_key]}_{m}', []) for batch_key in batch_cols.keys() for m in _metrics_per])\n",
    "## current version should give 4-entry dict for Icumul and Inew, with Dsearch and Dvalue each.\n",
    "\n",
    "def get_rename(b_label:str,\n",
    "               b_metric_mode:int) -> str:\n",
    "    # easy conversion of names for readable output\n",
    "\n",
    "    return f'{_out1_namemap[b_label]}_{_metrics_per[b_metric_mode]}'\n",
    "\n",
    "for _batch_label, _batch_metric in batch_cols.items():\n",
    "    # pivot raw results for efficient sorting\n",
    "    _pivot = batch_df.pivot(values=_batch_label, index='elapsed_nominal', columns='exp_id')\n",
    "    # 1st set of outputs for benchmarks-cum (reverse-find)\n",
    "    for _bench in _batch_metric:\n",
    "        _find_start = _pivot.apply(np.searchsorted, axis=0, v=_bench, side='left') - exps_s.c_nominal_ref_date\n",
    "        _statlabel: str = f'{get_rename(_batch_label, 0)}_{_bench}'\n",
    "        batch_out1[_statlabel] = _find_start\n",
    "        batch_names[get_rename(_batch_label, 0)].append(_statlabel)\n",
    "\n",
    "    # 2nd set of outputs for benchmarks-day\n",
    "    _statlabel: str = get_rename(_batch_label, 1)\n",
    "    _cols2 = [f'{_statlabel}_{bench}' for bench in benchmarks_day]\n",
    "    batch_out1[_cols2] = _pivot.loc[benchmarks_day, :].T\n",
    "    batch_names[get_rename(_batch_label, 1)] = _cols2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T11:06:50.734489Z",
     "start_time": "2023-10-16T11:06:50.630258400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "batch_to_excel = {}\n",
    "\n",
    "for _batch_name, _tables in batch_names.items():\n",
    "    # pivot again for output heatmapping\n",
    "    df2_piv_p = batch_out1.pivot(columns=['p_FlightBans_nom',],\n",
    "     index=['u_Rzero', 'u_ImportsIndirect'],\n",
    "     values=_tables)\n",
    "\n",
    "    # Original\n",
    "    # df2_piv_p = batch_out1.pivot(columns='p_FlightBans_nom',\n",
    "    #  index=['u_ImportsIndirect'],\n",
    "    #  values=_tables)\n",
    "    # df2_piv_ref = batch_out1[(batch_out1['p_FlightBans_nom'] == 0) & batch_out1['u_ImportsIndirect'] == 0.].pivot(columns='p_FlightBans_nom',\n",
    "    #                                                                                                                index=['u_Rzero','u_ImportsFlights', 'u_ImportsIndirect'],\n",
    "    #                                                                                                                values=tables) #.droplevel(1, axis=1)\n",
    "    # now need to collect all into nice metrics\n",
    "    # we have u_Rzero, u_imports, u_Flights\n",
    "    # r_rel_deltas = df2_piv_p.sub(df2_piv_ref, axis=1, level=0) #.drop(labels=0, level='u_ImportsIndirect', axis=1).astype(int)  # special stuff\n",
    "    # batch_to_reorder = {f'{_batch_name},cumulative_absolute': df2_piv_p,\n",
    "    #                   f'{_batch_name}, cumulative_relative': r_rel_deltas}\n",
    "    # batch_to_reorder =\n",
    "\n",
    "    # for name, mats in batch_to_reorder.items():\n",
    "    #     if _batch_name == 'b_cumulative':\n",
    "    #         batch_to_excel[name] = mats.stack(level=0)\\\n",
    "    #                 .reorder_levels([1,2,0], axis=0)\\\n",
    "    #                 .sort_index(axis=0)\n",
    "    #     elif _batch_name == 'b_day':\n",
    "    # batch_to_excel[_batch_name] = df2_piv_p\\\n",
    "    #     .reorder_levels([1,0,2], axis=0)\\\n",
    "    #     .sort_index(axis=0)\n",
    "        # .droplevel(level=0, axis=1)\\\n",
    "    batch_to_excel[_batch_name] = df2_piv_p.droplevel(level=0, axis=1)\\\n",
    "\n",
    "\n",
    "            # mats.unstack(level='u_ImportsFlights')\\\n",
    "            # .stack(level=0)\\\n",
    "            # .reorder_levels(['u_ImportsFlights', 'u_ImportsIndirect'], axis=1)\\\n",
    "            # .sort_index(axis=1)\\\n",
    "            # .reorder_levels([1, 0], axis=0)\\\n",
    "            # .sort_index(axis=0, level=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T11:06:51.465956500Z",
     "start_time": "2023-10-16T11:06:51.380187600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "with open(f'output_figures/{model_vers}/{model_vers}_Outputs{exps_filename}.tsv', 'w') as writefile:\n",
    "    for batch, stats in batch_to_excel.items():\n",
    "        writefile.write(f\"{batch}\\n\") # write batch name\n",
    "        stats.to_csv(writefile, sep='\\t', mode='a', lineterminator='\\n')  # append only\n",
    "        writefile.write('\\n\\n\\n')  # make some space"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-16T11:07:02.580118600Z",
     "start_time": "2023-10-16T11:07:02.508310300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# other stuff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "results_sectioned_melt = pd.melt(results_sectioned,\n",
    "                                 id_vars=['u_ImportsIndirect', 'elapsed_nominal'],\n",
    "                                 value_vars=['imported_direct',\n",
    "                                             'imported_indirect', ],\n",
    "                                 # 'infected_new'],\n",
    "                                 )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.scatterplot(results_sectioned_melt,\n",
    "                x='elapsed_nominal',\n",
    "                y='value',\n",
    "                hue='variable',\n",
    "                style='u_ImportsIndirect')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# look at imported values and their added case contributions\n",
    "# cumulative imports and cases (different scales though)\n",
    "# new added cases per compartment\n",
    "\n",
    "for metric in []:\n",
    "    pass\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# thinking how to plot the different stuff\n",
    "\n",
    "# could do cumulative per scenario?\n",
    "\n",
    "# look at added infections per scenario\n",
    "added_i_direct = results_s.pivot(values='direct', index='elapsed_nominal', columns='exp_id')\n",
    "meta_s['add_i_direct'] = added_i_direct.sum(axis=0)\n",
    "i_direct_cum = added_i_direct.cumsum(axis=0)\n",
    "\n",
    "added_i_indirect = results_s.pivot(values='indirect', index='elapsed_nominal', columns='exp_id')\n",
    "meta_s['add_i_indirect'] = added_i_indirect.sum(axis=0)\n",
    "i_indirect_cum = added_i_indirect.cumsum(axis=0)\n",
    "# uncertain: sensitivity?\n",
    "# cumulative number of imports per group (direct, indirect, 2ndary infections)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cum_total = results_s.pivot(values='cum_infected', index='elapsed_nominal', columns='exp_id')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# batch handling for tables: think about making into function form"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save batch df process modes\n",
    "\n",
    "batch_metrics = {\n",
    "    ('cum_infected', 50000): ('start_50000',),\n",
    "    ('infected_new', 5000): ('start_5000', 'duration_5000', 'max', 'max_day'),\n",
    "}\n",
    "\n",
    "batch_pivs_dict = {}\n",
    "batch_2ndary_dict = {}\n",
    "\n",
    "for metrics, metrics2 in batch_metrics.items():\n",
    "\n",
    "    metric, threshold = metrics\n",
    "\n",
    "    # metric = 'infected_new'\n",
    "    # threshold = 5000 # 50k for cumulative, 5k for duration\n",
    "    piv_p = results_s.pivot(values=metric, index='elapsed_nominal', columns='exp_id')\n",
    "    df_piv_p = post.add_threshold_time_search(df_to_search=piv_p,\n",
    "                                              df_to_add=meta_s,\n",
    "                                              threshold=threshold)\n",
    "    df_piv_p['u_ImportsInitial'] = df_piv_p['u_ImportsFlights'] + df_piv_p['u_ImportsIndirect']\n",
    "    # set up reference case\n",
    "    piv_r = results_r._pivot(values=metric, index='elapsed_nominal', columns='exp_id')\n",
    "    df_piv_r = post.add_threshold_time_search(df_to_search=piv_r,\n",
    "                                              df_to_add=meta_r,\n",
    "                                              threshold=threshold)\n",
    "    # ensuring equal comparison with the same initial import rate\n",
    "    # note hardcode at '-30' term\n",
    "    df_piv_r['u_ImportsInitial'] = df_piv_r['u_ImportsFlights'].copy()\n",
    "    # collect specific values\n",
    "    # values = f'start_{threshold}'  # for cumulative 50k\n",
    "    # values = f'duration_{threshold}'\n",
    "    batch_pivs_dict[metric] = {'pivot_p': piv_p,\n",
    "                               'pivot_r': piv_r,\n",
    "                               'df_piv_p': df_piv_p,\n",
    "                               'df_piv_r': df_piv_r\n",
    "                               }\n",
    "\n",
    "    # conduct 2ndary pivot to convert into matrix form\n",
    "    for metric2 in metrics2:\n",
    "        df2_piv_r = df_piv_r._pivot(columns='p_FlightBans_nom',\n",
    "                                    index=['u_Rzero', 'u_ImportsInitial'],\n",
    "                                    values=metric2)\n",
    "\n",
    "        df2_piv_p = df_piv_p._pivot(columns='p_FlightBans_nom',\n",
    "                                    index=['u_Rzero', 'u_ImportsInitial', 'u_ImportsFlights', 'u_ImportsIndirect'],\n",
    "                                    values=metric2)\n",
    "        df2_piv_p = df2_piv_p.drop(labels=1.1, level=0, errors='ignore')  # Custom addition\n",
    "\n",
    "        # get diff between\n",
    "        pr_deltas = df2_piv_p.sub(df2_piv_r[0], axis=0).dropna().drop(labels=0, level='u_ImportsIndirect').astype(int)\n",
    "\n",
    "        r_rel_deltas = df2_piv_p.diff(axis=1, periods=-1)\n",
    "\n",
    "        batch_2ndary_dict[(metric, metric2)] = {\n",
    "            'df2_piv_p': df2_piv_p,\n",
    "            'pr_deltas': pr_deltas,\n",
    "            'r_rel_deltas': r_rel_deltas,\n",
    "        }\n",
    "    #     break\n",
    "    # break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# output for excel\n",
    "# write into file?\n",
    "with open('output_figures/exps_post_Policies_small indirect_output.tsv', 'w') as writefile:\n",
    "    for batch, stats in batch_2ndary_dict.items():\n",
    "        for table_name, table in stats.items():\n",
    "            if 'max' in batch:  # special\n",
    "                table = table * 0.2 / 100  # hospitalisation\n",
    "            writefile.write(f\"{batch},{table_name}\\n\")\n",
    "            table.to_csv(writefile, sep='\\t', mode='a', lineterminator='\\n')  # append only\n",
    "            writefile.write('\\n\\n\\n')  # make some space\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# making graphs for importation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the importation scales on graph\n",
    "imports_nonflights = exps_s.i_nonflights_scaled  #.drop(labels=0, axis=1)\n",
    "imports_nonflights.index = imports_nonflights.index - exps_s.c_nominal_ref_date\n",
    "sns.lineplot(imports_nonflights)\n",
    "\n",
    "plt.title('Importation Functions into NL, different scales')\n",
    "plt.ylabel('Imports per day')\n",
    "plt.xlabel('Days since reference day (26th November 2021)')\n",
    "\n",
    "save_name = 'importation function scaled'\n",
    "plt.savefig(f'output_figures/plot_{exps_batchname}_{save_name}_full_linear.jpg', dpi=300)\n",
    "plt.xlim((None, 10))\n",
    "plt.savefig(f'output_figures/plot_{exps_batchname}_{save_name}_zoom_linear.jpg', dpi=300)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.gca().set_yticks(ticks=(0.1, 0.5, 1., 5, 10, 50, 100, 500, 1000))\n",
    "# plt.gca().tick_params(axis='y', which='minor',bottom=True)\n",
    "ticks_y = ticker.FuncFormatter(lambda x, pos: f'{float(x)}')\n",
    "plt.gca().yaxis.set_major_formatter(ticks_y)\n",
    "plt.ylabel('Imports per day (log)')\n",
    "plt.savefig(f'output_figures/plot_{exps_batchname}_{save_name}_zoom_log.jpg', dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make graphs for presentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dd_df2 = df_piv_p.groupby(by='u_Rzero', group_keys=True)\n",
    "temp_dict = {}\n",
    "temp_dict_rel = {}\n",
    "# get difference vs next import state\n",
    "# we know that the t_range stays almost constant\n",
    "\n",
    "metric = 'start_50000'\n",
    "for i, cat in enumerate(dd_df2):\n",
    "    name, group = cat\n",
    "\n",
    "    # get relative difference from nominal date\n",
    "    t_nom = group[group['p_FlightBans_nom'] == 0][metric].item()\n",
    "    # get subgroup:\n",
    "    t_weeks = group[group['p_FlightBans_nom'] % 7 == 0]\n",
    "    td_nom = t_weeks[metric] - t_nom\n",
    "    t_early = t_weeks[metric].max()\n",
    "    t_late = t_weeks[metric].min()\n",
    "    td_early = t_early - t_nom\n",
    "    td_late = t_late - t_nom\n",
    "    td_range = t_early - t_late\n",
    "\n",
    "    # get relative policy gain\n",
    "    td_rel = t_weeks.set_index('p_FlightBans_nom')[metric].diff(periods=-1)\n",
    "    td_rel_range = td_rel.max() - td_rel.min()\n",
    "    td_rel_avg = td_rel.mean()\n",
    "    td_rel_med = td_rel.median()\n",
    "\n",
    "    # write to dict\n",
    "    temp_dict[i] = {\n",
    "        'r0': name,\n",
    "        't_early': t_early,\n",
    "        't_nominal': t_nom,\n",
    "        't_late': t_late,\n",
    "        'td_early': td_early,\n",
    "        'td_late': td_late,\n",
    "        'td_range': td_range,\n",
    "        'td_rel_range': td_rel_range,\n",
    "        'td_rel_avg': td_rel_avg,\n",
    "        'td_rel_med': td_rel_med\n",
    "    }\n",
    "    temp_dict_rel[name] = td_rel\n",
    "    break\n",
    "\n",
    "# dd_df2_stats = pd.DataFrame.from_dict(temp_dict, orient='index')\n",
    "# dd_td_stats = pd.concat(temp_dict_rel, axis=1)\n",
    "\n",
    "# dd_df3 = dd_df2_stats.sort_values(by=['u_Rzero','p_FlightBans_nom'])\n",
    "# dd_df3 = dd_df2_stats[dd_df2_stats['import'].isin(ddelta_scenarios)].sort_values(by=['import','r0'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# new stuff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# collect indices of importance\n",
    "# we do single-variate analysis first, with 0-day case?\n",
    "d0_sens = results_s.loc[results_s.p_FlightBans == policy_inputs[0], :]\n",
    "# d0_sens['infected_cum_pct'] = d0_sens['cum_infected'] / exps_s.c_pop_total  # TODO move this to function form"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# we now isolate only the metric (cumulative infections) and relevant states: day, exp_id, policy/uncertainty\n",
    "# trim out, mostly for readability\n",
    "# d0_sens = d0_sens.loc[:, ['exp_id','elapsed_policy','imported','cum_infected', 'infected_total','infected_new']]\n",
    "# get u_REff from meta\n",
    "d0_meta = meta_s.loc[meta_s['p_FlightBans'] == policy_inputs[0], ['u_REff', 'u_NominalImports']]\n",
    "\n",
    "d0_p_imported = d0_sens._pivot(values='imported', index='elapsed_policy', columns='exp_id')\n",
    "d0_p_inf_cumulative = d0_sens._pivot(values='cum_infected', index='elapsed_policy', columns='exp_id')\n",
    "d0_p_inf_current = d0_sens._pivot(values='infected_total', index='elapsed_policy', columns='exp_id')\n",
    "# NB: seaborn prefers long data form for plotting!\n",
    "# TODO: verify if the u_NominalImports scaling is correct!\n",
    "# 50k-50k.. how to find?\n",
    "# top-down search and bottom-up search?\n",
    "threshold = 5000\n",
    "d0_m_inf_current = post.add_threshold_time_search(df_to_search=d0_p_inf_current,\n",
    "                                                  df_to_add=d0_meta,\n",
    "                                                  threshold=threshold)\n",
    "\n",
    "# make another m df for cumulative"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# d0_mat_duration = d0_m_inf_current.pivot(values=f'duration_{threshold}', index='u_REff', columns='u_NominalImports')\n",
    "# d0_mat_max = d0_m_inf_current.pivot(values='max', index='u_REff', columns='u_NominalImports')\n",
    "# d0_mat_maxday = d0_m_inf_current.pivot(values='max_day', index='u_REff', columns='u_NominalImports')\n",
    "# prolly can plot the max day and duration as a quadrant plot?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sensitivity: colour definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get categories from the experiment object\n",
    "s_R_categories = exps_s.PARAMS_RAW['u_REff']\n",
    "s_R_highlight = [1.1, 1.5, 2.0, 2.5, 3.0]  # hues to highlight\n",
    "s_R_dull_colour = 'silver'  # hues to keep in background\n",
    "s_R_ref_colour = {1.3: 'limegreen'}  # specific highlight for reference line (R=1.3)\n",
    "s_R_highlight_all = sorted(s_R_highlight + [1.3])\n",
    "\n",
    "# create custom palette for plotting\n",
    "palette_s = cmr.get_sub_cmap('cmr.guppy_r', start=0., stop=1., N=len(s_R_highlight))  # make colourful palette\n",
    "palette_s2 = dict((R, s_R_dull_colour) for R in s_R_categories)  # create all R-value categories in dull colours\n",
    "palette_s2.update(\n",
    "    dict(zip(s_R_highlight, palette_s.colors)))  #  change the highlighted categories to have bright colours\n",
    "palette_s2.update(s_R_ref_colour)  # change the colour of the reference line"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot : sensitivity analysis, R on total infectious people"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's try that map plot\n",
    "# plot start and end, with central point as max day\n",
    "# TODO: be careful that some inputs are floats and are not set to categorical form\n",
    "# TODO: convert scaling to percentage of population?\n",
    "plot_data = d0_m_inf_current.loc[(d0_m_inf_current['u_REff'] > 1.001) & (d0_m_inf_current['u_NominalImports'] == 15), :]\n",
    "# ad hoc additions\n",
    "plot_data = pd.melt(plot_data, id_vars=['u_REff', 'u_NominalImports', 'max_day', 'max'],\n",
    "                    value_vars=['start_5000', 'end_5000'],\n",
    "                    value_name='x')\n",
    "plot_data['max'] = plot_data['max'] / exps_s.c_pop_total\n",
    "# palette = cmr.get_sub_cmap('cmr.guppy_r', start=0.1, stop=0.9)\n",
    "fig1, ax1 = plt.subplots(figsize=(6, 6))\n",
    "plot_data = plot_data.rename(columns={'u_REff': 'R number',\n",
    "                                      'u_NominalImports': 'Total Imports'},\n",
    "                             )\n",
    "plot_duration = sns.lineplot(plot_data, x='x', y='max', ax=ax1, palette=palette_s2,\n",
    "                             hue='R number',  # style='Total Imports', dashes=dash_styles,\n",
    "                             linewidth=2.)\n",
    "plot_peaks = sns.scatterplot(plot_data, x='max_day', y='max', ax=ax1, palette=palette_s2, hue='R number', legend=False)\n",
    "# rename axis\n",
    "ax1.set_ylim(0, 1)\n",
    "ticks_y = ticker.FuncFormatter(lambda x, pos: f'{int(100 * x)}%')  # black magic\n",
    "ax1.yaxis.set_major_formatter(ticks_y)\n",
    "# ticks_x = ticker.FuncFormatter(lambda x, pos: f'{x/28}')\n",
    "# ax1.xaxis.set_major_formatter(ticks_x)\n",
    "ax1.set_xticks(ticks=range(0, 501, 30))\n",
    "\n",
    "ax1.set_ylabel('Peak infectious persons [% of total population]')\n",
    "ax1.set_xlabel('Days since start of entry restriction (26th November 2021)')\n",
    "ax1.set_title('Effect of R on outbreak period (line)\\n '\n",
    "              'and peak infectious persons (dot)\\n'\n",
    "              '(R = 1.3 as reference case)')\n",
    "\n",
    "# get legend handles\n",
    "h, l = ax1.get_legend_handles_labels()\n",
    "h = [h[k] for k, a in enumerate(l) if float(a) in s_R_highlight_all]\n",
    "ax1.legend(handles=h, labels=s_R_highlight_all, title='R number')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig1.savefig(f'output_figures/plot_sens_R_peak_duration_{model_vers}.jpg', dpi=300)\n",
    "# source: https://stackoverflow.com/questions/10171618/changing-plot-scale-by-a-factor-in-matplotlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sensitivity: plot truncated wave plot for cumulative infected people"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_data = d0_sens.loc[(d0_sens.u_NominalImports == 15) & (d0_sens.u_REff > 1.), :]\n",
    "renamer = {'u_REff': 'R number',\n",
    "           'cum_infected_pct': 'Percentage\\ninfected',\n",
    "           'elapsed_nominal': 'Days since reference date (26th Nov 2021)'}\n",
    "plot_data = plot_data.rename(columns=renamer)\n",
    "\n",
    "fig, ax4 = plt.subplots(figsize=(5, 6))\n",
    "sns.lineplot(plot_data, x=renamer['elapsed_nominal'], y=renamer['cum_infected_pct'],\n",
    "             hue=renamer['u_REff'], ax=ax4, palette=palette_s2)\n",
    "\n",
    "ax4.set_xlim(None, 190)\n",
    "ax4.set_xticks(range(-30, 211, 30))\n",
    "ticks_y = ticker.FuncFormatter(lambda x, pos: f'{int(x * 100)}%')\n",
    "ax4.yaxis.set_major_formatter(ticks_y)\n",
    "\n",
    "ax4.set_xlabel('Days since start of entry restriction (26th November 2021)')\n",
    "ax4.set_ylabel('Percentage of population infected')\n",
    "ax4.set_title('Effect of R on outbreak trajectory\\n'\n",
    "              '(R = 1.3 as reference case)')\n",
    "h, l = ax4.get_legend_handles_labels()\n",
    "h = [h[k] for k, a in enumerate(l) if float(a) in s_R_highlight_all]\n",
    "ax4.legend(handles=reversed(h), labels=reversed(s_R_highlight_all), title=\"R Number\")\n",
    "\n",
    "# ax4.legend(handles=reversed(h), labels=reversed(l),\n",
    "#            title='R number')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'output_figures/plot_sens, R on outbreak trajectory, {model_vers}.jpg', dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sensitivity: plot for import scaling on outbreak peak timing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "piv_p = results_s.pivot(values='infected_total', index='elapsed_nominal', columns='exp_id')\n",
    "threshold = 50000  # 50k\n",
    "df_piv_p = post.add_threshold_time_search(df_to_search=piv_p,\n",
    "                                          df_to_add=meta_s,\n",
    "                                          threshold=threshold)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot peak sizes here\n",
    "plot_data = df_piv_p.loc[df_piv_p['u_REff'] > 1.001, :]\n",
    "plot_data = plot_data.rename(columns={'u_REff': 'R number',\n",
    "                                      'u_NominalImports': 'Total Imports'})\n",
    "plot_data['max'] = plot_data['max'] / exps_s.c_pop_total\n",
    "scaling = 1\n",
    "# plot_sizes = {5: scaling,  # in pt\n",
    "#               10: 2 * scaling,\n",
    "#               15: 3 * scaling,\n",
    "#               20: 4 * scaling}\n",
    "\n",
    "plot_sizes = {imp: scaling * imp for imp in plot_data['Total Imports'].unique()}\n",
    "fig2, ax2 = plt.subplots(figsize=(6, 6))\n",
    "plot2_peaks = sns.scatterplot(plot_data, x='max_day', y='max', hue='R number',\n",
    "                              size='Total Imports', sizes=plot_sizes,\n",
    "                              ax=ax2, palette=palette_s2)\n",
    "\n",
    "ticks_y = ticker.FuncFormatter(lambda x, pos: f\"{int(x * 100)}%\")\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.yaxis.set_major_formatter(ticks_y)\n",
    "ax2.set_xticks(ticks=(range(0, 511, 30)))\n",
    "ax2.set_ylabel('Peak infectious persons [% total population]')\n",
    "ax2.set_xlabel('Days since start of flight restriction')\n",
    "ax2.set_title('Effect of R number and import scaling\\n'\n",
    "              'on outbreak peak timing and magnitude\\n'\n",
    "              '(total infectious persons)')\n",
    "\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "items = [1, 3, 5, 10, 15, 20]  # indices. hardcoded.\n",
    "handles_plt, labels_plt = zip(*[(handles[idx], labels[idx]) for idx in items])\n",
    "# labels_plt = [labels[idx] for idx in [0,2]]\n",
    "ax2.legend(handles=handles_plt, labels=labels_plt, title='R_number')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig2.savefig(f'output_figures/plot_sens_peak_timing, {model_vers}.jpg', dpi=300)\n",
    "del fig2, ax2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# specific plot for nominal case\n",
    "plot_ref = 1.3\n",
    "plot_data = df_piv_p.loc[df_piv_p['u_REff'] == plot_ref, :].copy()\n",
    "plot_data['max'] = plot_data['max'] / exps_s.c_pop_total\n",
    "rn = {'p_FlightBans': 'Entry Restriction Policy [day]',\n",
    "      'u_NominalImports': 'Total Imports'}\n",
    "plot_data = plot_data.rename(columns=rn)\n",
    "fig3, ax3 = plt.subplots(figsize=(5, 5))\n",
    "palette = 'cet_CET_R3'\n",
    "# 'blueviolet' reference\n",
    "palette_2 = dict((k, 'limegreen') for k in policy_inputs.values())\n",
    "f3_line = sns.lineplot(plot_data, x='max_day', y=rn['p_FlightBans'],\n",
    "                       hue=rn['p_FlightBans'], palette=palette_2, ax=ax3, legend=False, linewidth=3, zorder=0.9)\n",
    "f3_scatter = sns.scatterplot(plot_data, x='max_day', y=rn['p_FlightBans'], hue=rn['p_FlightBans'],\n",
    "                             size=rn['u_NominalImports'],\n",
    "                             palette=palette_2,\n",
    "                             ax=ax3, edgecolor='white', linewidth=1,\n",
    "                             legend=True, sizes=plot_sizes)\n",
    "\n",
    "ticks_y = ticker.FuncFormatter(lambda x, pos: f\"{int(x - exps_s.c_nominal_ref_date)}\")\n",
    "ax3.yaxis.set_major_formatter(ticks_y)\n",
    "ax3.invert_yaxis()\n",
    "ax3.yaxis.grid(False)\n",
    "\n",
    "# ax3.set_xticks(range(65, 101, 5))\n",
    "ax3.set_xlabel('Days from reference date (26th Nov 2021)')\n",
    "\n",
    "ax3.set_title('Effect of entry restriction timing '\n",
    "              'on day of infection peak,\\n'\n",
    "              'across different import rates '\n",
    "              f'(R = {plot_ref})')\n",
    "\n",
    "handles, labels = ax3.get_legend_handles_labels()\n",
    "ax3.legend(handles=handles[-6:], labels=labels[-6:], title='Total Imports')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig3.savefig(\n",
    "    f'output_figures/plot_sens, effect of policy on infection peak, zoom nominal, {model_vers}, {plot_ref}.jpg',\n",
    "    dpi=300)\n",
    "\n",
    "del ax3, fig3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sensitivity: plot: deltas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# group by R0 and nominal import scaling, trying to get the difference in TDD (time delta difference).\n",
    "# TDD describes the gain in days you get from having an earlier flight ban\n",
    "infc2_m_group = df_piv_p.groupby(by=['u_REff', 'u_NominalImports'], axis=0, group_keys=True)\n",
    "temp_dict = {}\n",
    "metric = 'start_50000'\n",
    "\n",
    "# isolate the start time of the outbreak\n",
    "for i, cat in enumerate(infc2_m_group):\n",
    "    name, group = cat\n",
    "    t_early = group[metric].min()\n",
    "    t_last = group[metric].max()\n",
    "    t_range = t_last - t_early\n",
    "\n",
    "    t_day_deltas = group[metric].diff(periods=-1)\n",
    "    tdd_avg = t_day_deltas.mean()\n",
    "    tdd_max = t_day_deltas.max()\n",
    "    tdd_min = t_day_deltas.min()\n",
    "    tdd_range = tdd_max - tdd_min\n",
    "\n",
    "    temp_dict[i] = {\n",
    "        'r0': name[0],\n",
    "        'import': name[1],\n",
    "        't_first': t_early,\n",
    "        't_last': t_last,\n",
    "        't_range': t_last - t_early,\n",
    "        'tdd_max': tdd_max,\n",
    "        'tdd_min': tdd_min,\n",
    "        'tdd_avg': tdd_avg,\n",
    "        'tdd_range': tdd_range,\n",
    "\n",
    "    }\n",
    "\n",
    "what_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n",
    "del temp_dict, metric, i, cat, name, group, t_early, t_last, t_range, t_day_deltas, tdd_min, tdd_max, tdd_avg, tdd_range"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we know that the t_range, tdd_avg, and tdd_range are the same across R0\n",
    "# the effect of importation is seen to only affect peak timing\n",
    "# however, the efficacy of the flight bans over longer durations is not visible, due to the short range of flight bans\n",
    "# how about difference of period between\n",
    "what_df['r0_plot'] = what_df.r0 + ((what_df['import'] // 15 - 4) / 120)\n",
    "what_df['category'] = [str(i) for i in list(zip(what_df['r0'], what_df['import']))]\n",
    "\n",
    "# massage common palette for plotting\n",
    "wdf_color_diff = list(zip(what_df['r0'], what_df['import'], what_df['category']))\n",
    "# create redundant palette\n",
    "wdf_palette = {}\n",
    "wdf_makeblack = [15, 120]\n",
    "for r0, imp, cat in wdf_color_diff:\n",
    "    if imp in wdf_makeblack:\n",
    "        wdf_palette[cat] = 'dimgray'\n",
    "    else:\n",
    "        wdf_palette[cat] = palette_s2[r0]\n",
    "\n",
    "what_df_melt = what_df.melt(id_vars=['r0_plot', 'r0', 'import', 'category'], value_vars=['t_first', 't_last'])\n",
    "fig, ax = plt.subplots(figsize=(4, 6))\n",
    "sns.lineplot(data=what_df_melt, x='value', y='r0_plot', hue='category', palette=wdf_palette, ax=ax, legend=False)\n",
    "\n",
    "ax.set_yticks(s_R_highlight_all)\n",
    "ax.set_xticks(range(0, 301, 60))\n",
    "ax.set_xlabel('Days since nominal')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make heatmap (due to large disparity in t_range)\n",
    "# we isolate for 5 scenarios: 1.1, 1.5, 2.0, 2.5, 3.0\n",
    "# look at t_range and tdd\n",
    "# r_range = [1.1, 1.5, 2., 2.5, 3.]\n",
    "# what_df_specific = what_df[what_df['r0'].isin(r_range)]\n",
    "# try plotting the TDDs\n",
    "\n",
    "# create redundant palette\n",
    "wdf_palette = {}\n",
    "wdf_makeblack = []\n",
    "for r0, imp, cat in wdf_color_diff:\n",
    "    if imp in wdf_makeblack:\n",
    "        wdf_palette[cat] = 'dimgray'\n",
    "    else:\n",
    "        wdf_palette[cat] = palette_s2[r0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clean up data for histogram/heatmap\n",
    "# we choose [15, 60, 120]\n",
    "# try to reference from nominal day\n",
    "# we want\n",
    "\n",
    "ddelta_scenarios = [15, 60, 120]\n",
    "ddelta_df = df_piv_p[df_piv_p['u_NominalImports'].isin(ddelta_scenarios)].drop(\n",
    "    columns=['p_FlightBans', 'u_TIncub', 'c_SimTime', 'c_PopTotal', 'c_model_engine'])\n",
    "ddelta_df['t_start_to_max'] = ddelta_df['max_day'] - ddelta_df['start_50000']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get relative day difference and day delta from nominal?\n",
    "# separate according to scenario\n",
    "\n",
    "dd_df2 = df_piv_p.groupby(by=['u_REff', 'u_NominalImports'], group_keys=True)\n",
    "temp_dict = {}\n",
    "temp_dict_rel = {}\n",
    "# get difference vs next import state\n",
    "# we know that the t_range stays almost constant\n",
    "\n",
    "metric = 'start_50000'\n",
    "for i, cat in enumerate(dd_df2):\n",
    "    name, group = cat\n",
    "    # get relative difference from nominal date\n",
    "    t_early = group[metric].max()\n",
    "    t_late = group[metric].min()\n",
    "    t_nom = group[group['p_FlightBans_nom'] == 0][metric].item()\n",
    "    td_early = t_early - t_nom\n",
    "    td_late = t_late - t_nom\n",
    "    td_range = t_early - t_late\n",
    "\n",
    "    # get relative policy gain\n",
    "    td_rel = group.set_index('p_FlightBans_nom')[metric].diff(periods=-1)\n",
    "    td_rel_range = td_rel.max() - td_rel.min()\n",
    "    td_rel_avg = td_rel.mean()\n",
    "    td_rel_med = td_rel.median()\n",
    "\n",
    "    temp_dict[i] = {\n",
    "        'r0': name[0],\n",
    "        'import': name[1],\n",
    "        't_early': t_early,\n",
    "        't_nominal': t_nom,\n",
    "        't_late': t_late,\n",
    "        'td_early': td_early,\n",
    "        'td_late': td_late,\n",
    "        'td_range': td_range,\n",
    "        'td_rel_range': td_rel_range,\n",
    "        'td_rel_avg': td_rel_avg,\n",
    "        'td_rel_med': td_rel_med\n",
    "    }\n",
    "    temp_dict_rel[name] = td_rel\n",
    "\n",
    "dd_df2_stats = pd.DataFrame.from_dict(temp_dict, orient='index')\n",
    "dd_td_stats = pd.concat(temp_dict_rel, axis=1)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(6,6))\n",
    "# sns.scatterplot(what_df, x='tdd_avg',\n",
    "#                 y='r0',\n",
    "#                 hue='category',\n",
    "#                 palette=wdf_palette,\n",
    "#                 legend=False,\n",
    "#                 linewidths=0.,\n",
    "#                 alpha=0.5,\n",
    "#                 ax=ax)\n",
    "# ax.set_yticks(s_R_highlight_all)\n",
    "# ax.set_xticks(range())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first isolate for t_nominal\n",
    "# what do I want to show? -> how lower R values lead to more effective flight bans\n",
    "# non-linear relationship\n",
    "# get dfs and save into excels?\n",
    "dd_df3 = dd_df2_stats[dd_df2_stats['import'].isin(ddelta_scenarios)].sort_values(by=['import', 'r0'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dd_df3.to_csv('output_figures/dd_df_scenarios.csv', sep=',', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
